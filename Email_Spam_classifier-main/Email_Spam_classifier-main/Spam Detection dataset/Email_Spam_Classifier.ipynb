{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "af95bb53-f39f-4269-b7a5-f49504846f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "20806c25-6acb-4262-84d8-d4b2c75e8643",
   "metadata": {},
   "outputs": [],
   "source": [
    "Emails = pd.read_csv(\"spam_Classifier_datasets.csv\", encoding='latin-1')\n",
    "\n",
    "Emails.rename(columns = {'v1':'target','v2':'text'},inplace = True)\n",
    "Emails.drop(columns = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace = True)\n",
    "\n",
    "for i in range(len(Emails['target'])):\n",
    "    if Emails.at[i,'target'] == 'ham':\n",
    "        Emails.at[i,'target'] = 0\n",
    "    if Emails.at[i,'target'] == 'spam':\n",
    "        Emails.at[i,'target'] = 1\n",
    "\n",
    "Emails.duplicated().sum() #  checking if our data has duplicates row or not\n",
    "\n",
    "Emails.drop_duplicates(keep='first') # removing the duplicate rows\n",
    "\n",
    "X = Emails['text']\n",
    "y = Emails['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d29553-8edd-44e3-b377-657f63411b73",
   "metadata": {},
   "source": [
    "# PREPROCESSING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d295ef90-cd60-4bfe-985e-c88ae03487de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Into_lowercase(text):\n",
    "    text = text.lower()\n",
    "    return text\n",
    "    \n",
    "def remove_special_char(text):\n",
    "    r_text = []\n",
    "    text = text.split()\n",
    "    for i in text:\n",
    "        if i.isalpha():\n",
    "            r_text.append(i)\n",
    "\n",
    "    r_text = \" \".join(r_text)\n",
    "    return r_text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = {\n",
    "        'a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', 'as', 'at',\n",
    "        'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by',\n",
    "        'could', 'did', 'do', 'does', 'doing', 'down', 'during',\n",
    "        'each', 'few', 'for', 'from', 'further',\n",
    "        'had', 'has', 'have', 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how',\n",
    "        'i', 'if', 'in', 'into', 'is', 'it', 'its', 'itself',\n",
    "        'just',\n",
    "        'me', 'more', 'most', 'my', 'myself',\n",
    "        'no', 'nor', 'not',\n",
    "        'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', 'ours', 'ourselves', 'out', 'over', 'own',\n",
    "        'same', 'she', 'should', 'so', 'some', 'such',\n",
    "        'than', 'that', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too',\n",
    "        'under', 'until', 'up',\n",
    "        'very',\n",
    "        'was', 'we', 'were', 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'with', 'would',\n",
    "        'you', 'your', 'yours', 'yourself', 'yourselves'\n",
    "    }\n",
    "\n",
    "    r_text = []\n",
    "    text = text.split()\n",
    "    for i in text:\n",
    "        if i not in stop_words:\n",
    "            r_text.append(i)\n",
    "\n",
    "    r_text = \" \".join(r_text)\n",
    "    return r_text\n",
    "\n",
    "def lemmatization(text):\n",
    "    suffixes = [\"ing\", \"ed\", \"ly\", \"es\", \"s\"]\n",
    "\n",
    "    r_text = []\n",
    "    text = text.split()\n",
    "    for i in text:\n",
    "        if i.endswith(\"ing\"):\n",
    "            i = i[0:-3]\n",
    "            r_text.append(i)\n",
    "\n",
    "        elif i.endswith(\"ed\"):\n",
    "            i = i[0:-2]\n",
    "            r_text.append(i)\n",
    "\n",
    "        elif i.endswith(\"ly\"):\n",
    "            i = i[0:-2]\n",
    "            r_text.append(i)\n",
    "\n",
    "        elif i.endswith(\"es\"):\n",
    "            i = i[0:-2]\n",
    "            r_text.append(i)\n",
    "\n",
    "        elif i.endswith(\"s\"):\n",
    "            i = i[0:-1]\n",
    "            r_text.append(i)\n",
    "\n",
    "        else:\n",
    "            r_text.append(i)\n",
    "\n",
    "    r_text = \" \".join(r_text)\n",
    "    return r_text\n",
    "\n",
    "def tokenization(text):\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "def Preprocessing(text):\n",
    "    text = Into_lowercase(text)\n",
    "    text = remove_special_char(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = lemmatization(text)\n",
    "    text = tokenization(text)\n",
    "\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c9a998-aa61-4bd8-ae17-ea0c74a95e47",
   "metadata": {},
   "source": [
    "# WORD DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ba313165-9c20-48f4-bca3-3bc0c1c2a77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwords_dict = []\\nX_new = []\\nfor i in range(len(X)):\\n    refine_mail = Preprocessing(X[i])\\n    X_new.append(refine_mail)\\n\\n\\nfor email in X_new:\\n    for words in email:\\n        if words not in words_dict:\\n            words_dict.append(words)\\n\\nprint(words_dict)\\nlen(words_dict)\\n'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "words_dict = []\n",
    "X_new = []\n",
    "for i in range(len(X)):\n",
    "    refine_mail = Preprocessing(X[i])\n",
    "    X_new.append(refine_mail)\n",
    "\n",
    "\n",
    "for email in X_new:\n",
    "    for words in email:\n",
    "        if words not in words_dict:\n",
    "            words_dict.append(words)\n",
    "\n",
    "print(words_dict)\n",
    "len(words_dict)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a2175-b522-479d-9f4f-a5b25fe07afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc63674-c313-4d16-af24-8870db3780cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "445fddf7-ce75-4b30-9dc0-17d4af5bea3b",
   "metadata": {},
   "source": [
    "# Converting Text to Numerical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "505b2696-6b73-4773-a3a3-5be5c95a83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c4bc6d72-d25f-44a9-b130-d3bd1289ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_new = [Preprocessing(email) for email in X]\n",
    "\n",
    "# Use CountVectorizer to quickly convert to numerical features\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "Numerical_feature = vectorizer.fit_transform(X_new).toarray()\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6137aee4-8e06-49f7-bc97-7e695b725cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2871880531311035\n"
     ]
    }
   ],
   "source": [
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a903e95a-00ef-4f4d-a3c6-b993c43f7052",
   "metadata": {},
   "outputs": [],
   "source": [
    "Numerical_feature = np.array(Numerical_feature)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "49a72e3c-629e-4293-9d49-d32c667973e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5191)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Numerical_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ddb8653b-dd6a-4d02-a2f4-a10a9d7ba861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6bf37f5d-9c28-44eb-8de6-ab5750b4226d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(4457,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Numerical_feature, y, test_size = 0.2, random_state = 9)\n",
    "print(type(y_train))\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f48b8494-4569-4d4b-8217-59f37c15704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "418f382f-5967-41db-8b28-c3e072438770",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "954b684e-ec9f-4039-a7c0-fe632c9f03c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([0, 0, 0, ..., 0, 0, 0], dtype=object),)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[141], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:736\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    733\u001b[0m _, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    735\u001b[0m labelbin \u001b[38;5;241m=\u001b[39m LabelBinarizer()\n\u001b[1;32m--> 736\u001b[0m Y \u001b[38;5;241m=\u001b[39m \u001b[43mlabelbin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m labelbin\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:329\u001b[0m, in \u001b[0;36mLabelBinarizer.fit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[0;32m    310\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit label binarizer/transform multi-class labels to binary labels.\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \n\u001b[0;32m    312\u001b[0m \u001b[38;5;124;03m    The output of transform is sometimes referred to as\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;124;03m        will be of CSR format.\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:306\u001b[0m, in \u001b[0;36mLabelBinarizer.fit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my has 0 samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y)\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse_input_ \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39missparse(y)\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[43munique_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:106\u001b[0m, in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m    104\u001b[0m _unique_labels \u001b[38;5;241m=\u001b[39m _FN_UNIQUE_LABELS\u001b[38;5;241m.\u001b[39mget(label_type, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _unique_labels:\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mrepr\u001b[39m(ys))\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_array_api_compliant:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;66;03m# array_api does not allow for mixed dtypes\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     unique_ys \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mconcat([_unique_labels(y) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m ys])\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: (array([0, 0, 0, ..., 0, 0, 0], dtype=object),)"
     ]
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c1f8062b-2c2e-4f75-84f4-863581f17797",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultinomialNB' object has no attribute 'feature_log_prob_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[119], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:102\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    100\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    101\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X(X)\n\u001b[1;32m--> 102\u001b[0m jll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_joint_log_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(jll, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\naive_bayes.py:896\u001b[0m, in \u001b[0;36mMultinomialNB._joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_joint_log_likelihood\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    895\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculate the posterior log probability of the samples X\"\"\"\u001b[39;00m\n\u001b[1;32m--> 896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_log_prob_\u001b[49m\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_log_prior_\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MultinomialNB' object has no attribute 'feature_log_prob_'"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6a8ce791-4ebd-4e1c-8371-d740c6264056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0b7ed95e-bbe5-408c-8681-6042bbe1977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3b1939d5-a512-4c1f-9789-1175885c5cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5672606391954373\n"
     ]
    }
   ],
   "source": [
    "r2_score = r2_score(y_test, y_pred)\n",
    "print(r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d9fbdf-c198-407f-b87f-06ebedeac5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7f5a79-1d73-49ae-aca5-c88d6f26b670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
